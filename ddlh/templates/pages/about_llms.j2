{% extends "layouts/main.j2" %}
{% block main %}
    <div class="theme-tag-document-header container">
        <h1>About our use of Large Language Models</h1>
    </div>
    <div class="static-page-content container">
        <p>
            The Distributed Design Learning Hub relies on both editorial content and curation, and the use of <strong>Large Language Models (LLMs)</strong> to help assist with discovering information and resources in the Distributed Design Platform archive.
        </p>
        <p>
            <strong>Wherever you see text that is<span class="robot-text"><span class="emoji">âœ¨</span> set in a light blue colour, preceded by the "sparkle" emoji</span>, that text has been generated by an LLM</strong>. Such text will always be preceded by a notice linking to this page for further details. Any other content you see on this site has been written, by hand, by a subject-matter expert from the Distributed Design Platform community. At present, LLM-generated text is only used in the responses generated for queries for custom themes, using the search box on the homepage.
        </p>
        <p>
            LLM generated text will always be an automatically generated <strong>summary</strong> of some content from within the Distributed Design Platform archive, and the sources used to generate it will always be linked and prominently referenced.
        </p>
        <p>
            <strong>If you encounter any LLM generated content which you believe to be inaccurate, discriminatory, or harmful, please <a href="https://airtable.com/appE3FwwATH2Ul3RR/pagMZlVZfvVtZclhU/form"
    target="_blank">report it to us using the feedback form</a>, and we will review it and take action.</strong>
        </p>
        <h2>Some tips for working with LLM generated summaries</h2>
        <ul>
            <li>
                <strong>Always corroborate information using the referenced sources</strong>. Our summaries are intended as an aid to discovery, not as a source of factual information in their own right. Use them to guide your research, but please click through to the referenced resource to verify any factual claims.
            </li>
            <li>
                Bear in mind that <strong>summaries are based on the information in the Distributed Design Platform archive</strong>, and as such, reflect the research, interests, and knowledge of our community in particular. Summaries for broad themes and topics will reflect our community's engagement with them, not give an entire overview of the field.
            </li>
            <li>
                <strong>Always verify factual claims, particularly those liable to change over time</strong>. Our archive contains the archive of outputs of more than 10 years of research, and a lot can change over that time. Please do further research to check that the summarised information is still current!
            </li>
        </ul>
        <h2>Our commitment to responsible use of machine learning technologies</h2>
        <p>
            We are committed to using machine learning technologies such as LLMs in a way which is consistent with the principles of Distributed Design, and to taking concrete steps to mitigate the ecolological and social harms to which they can give rise.
        </p>
        <p>In particular, we aim to use LLMs in a way which is:</p>
        <ul>
            <li>
                <strong>Transparent</strong>, both in the sense that text generated using an LLM should be explicitly marked as such, and that the processes, algorithms, and data used to generate the text shuold be explained publicly and understandably. In addition, we aim to be explicit about the limitations of such text in terms of its accuracy or comprehensiveness.
            </li>
            <li>
                <strong>Responsible</strong>, in that we take concrete steps to mitigate the social and environmental risks that LLMs and other machine learning technologies have the potential to present.
            </li>
            <li>
                <strong>Complementary</strong> to our knowledge and skills, and those of the wider Distributed Design community. Our use of LLMs is not intended to replace or supplant domain knowledge or editorial skills, but to augment them.
            </li>
        </ul>
        <p>
            We do so through our choice of technologies: We selected the  <a href="https://mistral.ai/news/mixtral-8x22b/" target="_blank">mixtral-8x-22B</a> model not just for its performance, but also because it <a href="https://docs.mistral.ai/capabilities/guardrailing/"
    target="_blank">offers robust guardrails against discriminatory and harmful content</a> and is <a href="https://mistral.ai/news/mixtral-8x22b/" target="_blank">requires less computational power</a>, and therefore material resources, than other similar models.
        </p>
        <p>
            In addition, this commitment is reflected as a design concern: We use LLMs only as a fallback to generate specific content when we do not have content already available, and we cache responses to ensure that the amount of text generated is kept to a minimum. In addition, our strategy of producing only successive summaries of text from within the Distributed Design platform archive cuts down on the likelihood that discriminatory or harmful content is generated.
        </p>
        <p>
            Finally, we have tested and audited the system for bias and harm pre-launch, and review all generated content on an ongoing basis for accuracy and fairness. We hope that as well as providing a useful service, the Distributed Design Learning Hub might also serve as an example of best-practice for incorporating machine learning technologies in projects in a way that reflects and respects the values of the Distributed Design community.
        </p>
        <h2>How we use LLMs to generate summaries</h2>
        <p>
            The Learning Hub search interface operates, broadly, as a <a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation"
    target="_blank">Retrieval-Augmented Generation (RAG)</a> system.
        </p>
        <p>
            Our editorial team have written, by hand, a summary for each document in the Learning Hub archive, and categorised them by hand into thematic areas, and more general tags. This editorial content, plus the text of the document itself, is used to create <strong>embeddings</strong> - mathematical representations of portions of the document which can be compared to each other (and to text queries) in a way that allows us to query the resulting database by semantic similarity.
        </p>
        <p>
            When you search for a custom theme, using the search form on the homepage, your query is also converted into an embedding, from which we retrieve the most similar document fragments to your query (each of them scored by how similar it is). We then collate these by the documents that they were taken from, and sort them so that the most similar document appears first - these are the search results you see alongside the summary on the results page.
        </p>
        <p>
            For theses documents we then provide the text of the retrieved fragments to a language model, along with a prompt to summarise how topic of your query is addressed in the document. Any documents with no relevant information are summarised, and we continue down the list until we have a maximum of three summaries. These are then presented back to you, along with links to the source.
        </p>
        <p>
            Finally, we provide the text of all the fragments of the summarised documents to the language model, along with a prompt to summarise the topic in general, using the information provided. This is added as the first sentence to the summary.
        </p>
        <p>
            For those who want more technical details: our embeddings are created with the <a href="https://docs.mistral.ai/getting-started/models/"
    target="_blank">mistral-embed</a> model, stored in an <a href="https://www.elastic.co/" target="_blank">elasticsearch</a> database, and similarity is measured by cosine distance between the query and the fragment. We use the <a href="https://mistral.ai/news/mixtral-8x22b/" target=""_blank">mixtral-8x-22B</a> large language model to generate summaries, and <a href="https://docs.llamaindex.ai/en/stable/" target="_blank">llama_index</a> as plumbing for the whole system. The entire application is open source, and <a href="https://github.com/fablabbcn/distributed-design-learning-hub/"
    target="_blank">available on Github</a>.
        </p>
    </div>
{% endblock main %}
